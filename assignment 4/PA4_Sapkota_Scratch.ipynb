{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the CSV. And it does have a header\n",
    "dataset = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting input and target\n",
    "X = dataset.iloc[:,0:-1]\n",
    "y = dataset.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting the Training Test Data\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "#coverting to floate so standard scalar wouldn't complain\n",
    "XTrain = XTrain.astype(np.float64)\n",
    "XTest = XTest.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()  \n",
    "scaler.fit(XTrain)\n",
    "XTrain = scaler.transform(XTrain)  \n",
    "XTest = scaler.transform(XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AdaBoostClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-274c76c30282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#creating adaboost sklearn and fitting it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     ADBC = AdaBoostClassifier(\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mSGDClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'log'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AdaBoostClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "Acc_Sc_Ad_Train = []\n",
    "Acc_Sc_Ad_Test = []\n",
    "Acc_Sc_Bl_Train = []\n",
    "Acc_Sc_Bl_Test = []\n",
    "\n",
    "for i in range(100):\n",
    "    #creating adaboost sklearn and fitting it\n",
    "    ADBC = AdaBoostClassifier(\n",
    "        DecisionTreeClassifier(max_depth=3),\n",
    "        n_estimators= i+1,\n",
    "        learning_rate=1.5,\n",
    "        algorithm=\"SAMME.R\")\n",
    "    ADBC.fit(XTrain,yTrain)\n",
    "    \n",
    "    #only using base classifier\n",
    "    BL = DecisionTreeClassifier(max_depth=3) \n",
    "    BL.fit(XTrain, yTrain) \n",
    "    \n",
    "    predTrainAda = ADBC.predict(XTrain)\n",
    "    predTestAda = ADBC.predict(XTest)\n",
    "    predTrainBL = BL.predict(XTrain)\n",
    "    predTestBL = BL.predict(XTest)\n",
    "    \n",
    "    Acc_Sc_Ad_Train.append(accuracy_score(yTrain, predTrainAda))\n",
    "    Acc_Sc_Ad_Test.append(accuracy_score(yTest, predTestAda))\n",
    "    Acc_Sc_Bl_Train.append(accuracy_score(yTrain, predTrainBL))\n",
    "    Acc_Sc_Bl_Test.append(accuracy_score(yTest, predTestBL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Acc_Sc_Bl_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(num=None, figsize=(18, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.ylim(0,1.2)\n",
    "plt.grid(which=\"major\", alpha=0.2)\n",
    "plt.grid(which=\"minor\", alpha=0.5)\n",
    "plt.plot(range(1,101),Acc_Sc_Ad_Train,'*-',\n",
    "        range(1,101),Acc_Sc_Ad_Test,'*b-')\n",
    "#         range(1,101),Acc_Sc_Bl_Train,\n",
    "#         range(1,101),Acc_Sc_Bl_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaBoostFromScratch(X,y, M=10, learning_rate = 1.5):\n",
    "    #Initialization of utility variables\n",
    "    N = len(y)\n",
    "    estimator_list, y_predict_list, estimator_error_list, estimator_weight_list, sample_weight_list = [], [],[],[],[]\n",
    "\n",
    "    #Initialize the sample weights\n",
    "    sample_weight = np.ones(N) / N\n",
    "    sample_weight_list.append(sample_weight.copy())\n",
    "\n",
    "    #For m = 1 to M\n",
    "    for m in range(M):   \n",
    "\n",
    "        #Fit a classifier\n",
    "        estimator = DecisionTreeClassifier(max_depth = 1, max_leaf_nodes=2)\n",
    "        estimator.fit(X, y, sample_weight=sample_weight)\n",
    "        y_predict = estimator.predict(X)\n",
    "\n",
    "        #Misclassifications\n",
    "        incorrect = (y_predict != y)\n",
    "\n",
    "        #Estimator error\n",
    "        estimator_error = np.mean( np.average(incorrect, weights=sample_weight, axis=0))\n",
    "        \n",
    "        #Boost estimator weights\n",
    "        estimator_weight =  learning_rate * np.log((1. - estimator_error) / estimator_error)\n",
    "\n",
    "        #Boost sample weights\n",
    "        sample_weight *= np.exp(estimator_weight * incorrect * ((sample_weight > 0) | (estimator_weight < 0)))\n",
    "\n",
    "        #Save iteration values\n",
    "        estimator_list.append(estimator)\n",
    "        y_predict_list.append(y_predict.copy())\n",
    "        estimator_error_list.append(estimator_error.copy())\n",
    "        estimator_weight_list.append(estimator_weight.copy())\n",
    "        sample_weight_list.append(sample_weight.copy())\n",
    "        \n",
    "\n",
    "\n",
    "    #Convert to np array for convenience   \n",
    "    estimator_list = np.asarray(estimator_list)\n",
    "    y_predict_list = np.asarray(y_predict_list)\n",
    "    estimator_error_list = np.asarray(estimator_error_list)\n",
    "    estimator_weight_list = np.asarray(estimator_weight_list)\n",
    "    sample_weight_list = np.asarray(sample_weight_list)\n",
    "\n",
    "    #Predictions\n",
    "    preds = (np.array([np.sign((y_predict_list[:,point] * estimator_weight_list).sum()) for point in range(N)]))\n",
    "    print('Accuracy = ', (preds == y).sum() / N) \n",
    "    \n",
    "    return estimator_list, estimator_weight_list, sample_weight_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
